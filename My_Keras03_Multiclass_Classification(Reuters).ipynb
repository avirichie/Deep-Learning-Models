{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My_Keras03-Multiclass_Classification(Reuters).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMzktK5OQbdiW5xg/YN0V9f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avirichie/Deep-Learning-Models/blob/master/My_Keras03_Multiclass_Classification(Reuters).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN4ru3HXvBNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "(X_train,Y_train),(X_test,Y_test) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUV_D9kjwLHm",
        "colab_type": "code",
        "outputId": "f22c15b0-8fd9-4278-c353-b8dfed7fa7a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8982,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FkmmdaBwh8t",
        "colab_type": "code",
        "outputId": "b6e1f3b3-7e38-4040-ba6f-4532767d92e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2246,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-l5EH6gCB73",
        "colab_type": "text"
      },
      "source": [
        "You canâ€™t feed lists of integers into a neural network. You have to turn your lists into tensors. There are two ways to do that:\n",
        "\n",
        "Pad your lists so that they all have the same length, turn them into an integer tensor of shape (samples, word_indices), and then use as the first layer in your network a layer capable of handling such integer tensors.\n",
        "\n",
        "One-hot encode your lists to turn them into vectors of 0s and 1s. This would mean, for instance, turning the sequence [3, 5] into a 10,000-dimensional vector that would be all 0s except for indices 3 and 5, which would be 1s. Then you could use as the first layer in your network a Dense layer, capable of handling floating-point vector data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U0uY2fr_cYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vectorize the Training data\n",
        "import numpy as np \n",
        "\n",
        "def Vectorize(sequences,dimensions=10000):\n",
        "  results=np.zeros((len(sequences),dimensions))\n",
        "  for i,sequence in enumerate(sequences):\n",
        "    results[i,sequence]=1\n",
        "  return results\n",
        "\n",
        "X_train_vec = Vectorize(X_train)\n",
        "X_test_vec = Vectorize(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuDPJh3-wnf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting the list of integers into tensors\n",
        "from tensorflow.keras.utils import to_categorical #Donot use np.utils here because its internal and cant be accessed publically, Thus import it just using utils and not utils.nputils\n",
        "\n",
        "one_hot_Y_train =to_categorical(Y_train)\n",
        "one_hot_Y_test  =to_categorical(Y_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AAlDdhczOju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(128,activation='relu',input_shape=(10000,)))\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "model.add(layers.Dense(46,activation='softmax')) # The last layer should have the 46 nodes because we have to classify the training example into 46 different categories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss7uXGc-94Hx",
        "colab_type": "text"
      },
      "source": [
        "The best loss function to use in this case is categorical_crossentropy. It measures the distance between two probability distributions: here,\n",
        "between the** probability distribution output by the network** and **the true distribution of the labels**. By minimizing the distance between these two distributions, you train the network to output something as close as possible to the true labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wh73iaJ9MAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkCcSYGo9ysB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = X_train_vec[:1000]\n",
        "partial_X_train = X_train_vec[1000:]\n",
        "\n",
        "Y_val = one_hot_Y_train[:1000]\n",
        "partial_Y_train = one_hot_Y_train[1000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bd38kIPDKwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x=X_train_vec,\n",
        "                    y=one_hot_Y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val,Y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKLP42e2EZvf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "The model after 50 epochs has a training accuracy of 95.81% and validation accuracy of 97.50%. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yY0DmoxDqU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8dfe17a4-ea61-45f0-fcef-6ad8a8e46c9a"
      },
      "source": [
        "final_results =  model.evaluate(X_test_vec,one_hot_Y_test)\n",
        "print(final_results)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2246/2246 [==============================] - 0s 155us/sample - loss: 3.1988 - acc: 0.7707\n",
            "[3.198813250737857, 0.7707035]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOf0klWvIaTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(X_test_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ_hjfQeKVkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f01e10a-61a9-46d9-b06b-bb1fde1ae941"
      },
      "source": [
        "predictions[0].shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe5fP5bLKYsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86a7fb08-d44f-49b6-e942-aaf577c682d4"
      },
      "source": [
        "np.argmax(predictions[0]) # The class with highest probability "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uplO_y-PaI4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}